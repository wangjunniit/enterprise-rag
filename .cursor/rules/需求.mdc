---
alwaysApply: true
---
# 我想做一个企业内部使用的rag应用  
# 主要功能如下  
1. 指定一个目录，递归读取目录下的所有文档(txt、word、excel、pdf、markdown等常见的格式)，将读取到的内容进行分割和向量化处理，将向量化内容存入数据库  
2. 根据用户提出的问题做向量召回和llm推理，回答用户的问题  

# 技术选型  
## 开发语言  
python
## 文本向量化使用的模型
Qwen/Qwen3-Embedding-0.6B
## 向量数据库
pgvector
## 重排序使用的模型
Qwen/Qwen3-Reranker-0.6B
## LLM使用的模型
Qwen/Qwen3-0.6B

# 流程
1. 文档预处理：解析企业文档（txt、word、excel、pdf、markdown等等）。
2. 向量化：用 Qwen3-Embedding-0.6B 将文档分块和查询转换为向量。
3. 存储：将向量和元数据存储到 pgvector。
4. 检索：用户查询生成向量，从 pgvector 检索 Top-K 文档。
5. 重排序：用 Qwen3-Reranker-0.6B 对 Top-K 文档重新排序，选出 Top-5。
6. 生成：将重排序后的上下文注入 Qwen3-0.6B 的 Prompt，生成答案。
7. 接口：使用 FastAPI 封装 RAG 系统，提供 REST API。

# 技术细节
## 文档解析统一接口
langchain_community.document_loaders
## 文件解析使用的库
- PDF：PyMuPDF
- Word：python-docx
- Excel：pandas
- Markdown：markdown
- 图片/OCR：pytesseract、unstructured
## 文档分块的粒度和重叠
可配置，默认每块400 tokens，重叠100 tokens，优先按段落分块，段落过长则再切分。分块时保留原文的起止字符位置，便于后续高亮和原文定位。
## 元数据设计
存储到pgvector时，为每个分块保存文档名、路径、页码、段落号等元数据，便于后续溯源和展示
## 表结构
CREATE TABLE documents_chunk (
    id SERIAL PRIMARY KEY,                -- 主键
    document_id TEXT,                     -- 文档唯一标识（如UUID或哈希）
    version INT DEFAULT 1,                -- 文档版本号，默认为1
    document_name TEXT,                   -- 文档名
    document_path TEXT,                   -- 文档路径
    page_num INT,                         -- 页码（如有）
    paragraph_num INT,                    -- 段落号（如有）
    chunk_index INT,                      -- 分块序号
    content TEXT,                         -- 分块文本内容
    embedding VECTOR(768),                -- 向量（假设Qwen3-Embedding-0.6B输出为768维）
    created_at TIMESTAMP DEFAULT NOW(),   -- 创建时间
    extra_metadata JSONB                  -- 其他可扩展元数据（如文档类型、作者等）
);
CREATE INDEX ON documents_chunk USING hnsw (embedding vector_cosine_ops);
CREATE INDEX idx_document_id ON documents_chunk(document_id);
## 检索与重排序
- Top-K的K值建议可配置。
- 需要多轮对话上下文，拼接轮数可配置，默认5轮，拼接格式：每轮一行，区分用户和助手，最大token数：800.
- 截断策略：优先保留最近的对话，从最新一轮往前拼接，直到达到最大轮数或Prompt长度限制，如遇到Prompt长度超限，可先限制轮数，再对每轮内容做截断。
## LLM与推理
推理接口是python直接调用模型，超时重试次数可配置。
## Prompt模板
你是企业知识库智能助手，请严格根据下列资料内容回答用户问题。
如资料中未提及，请回复“未找到相关信息”，不要编造答案。
如有多条信息请用分点或表格展示，答案后请注明引用的资料出处（如文档名、页码、段落号）。

【历史对话】
{history}

【参考资料】
1. {chunk_content_1}
   出处：{doc_name_1}，页码：{page_num_1}，段落：{para_num_1}
2. {chunk_content_2}
   出处：{doc_name_2}，页码：{page_num_2}，段落：{para_num_2}
...

【用户问题】
{question}

【你的回答】
## API设计
暂时只需要一个最小可用的demo
## 部署与运维
暂时只需要一个最小可用的demo
## 性能与安全
暂时只需要一个最小可用的demo
## 支持定时/增量同步目录下新文档
是，提供好接口即可，我自己调用
## 检索结果的可视化展示（如高亮、原文定位）
是
## 支持多语言文档
是